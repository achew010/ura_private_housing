{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "def get_api_key():\n",
    "    \"\"\"\n",
    "    Load the API key from the environment variables.\n",
    "    \"\"\"\n",
    "    access_key = os.getenv('URA_ACCESS_KEY')\n",
    "    token = os.getenv('URA_API_TOKEN')\n",
    "    if not access_key or not token:\n",
    "        raise Exception(\"API keys not found. Make sure you have set it in the .env file.\")\n",
    "    return {'access_key': access_key, 'token': token}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_ura_data(access_key, token, batch_number=1):\n",
    "    \"\"\"\n",
    "    Fetch data from the URA API using access key and token.\n",
    "\n",
    "    Parameters:\n",
    "        access_key (str): The access key for the URA API.\n",
    "        token (str): The token for the URA API.\n",
    "        batch_number (int): The batch number to request, default is 1.\n",
    "\n",
    "    Returns:\n",
    "        dict: The response data in JSON format if successful.\n",
    "    \"\"\"\n",
    "    url = f\"https://www.ura.gov.sg/uraDataService/invokeUraDS\"\n",
    "    \n",
    "    params = {\n",
    "        \"service\": \"PMI_Resi_Transaction\",\n",
    "        \"batch\": batch_number\n",
    "     }\n",
    "\n",
    "    # Set the headers with the access key and token\n",
    "    headers = {\n",
    "        \"User-Agent\": 'PostmanRuntime/7.28.4',\n",
    "        \"AccessKey\": access_key,\n",
    "        \"Token\": token\n",
    "    }\n",
    "\n",
    "    # Make the GET request\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        return response.json()  # Return the JSON data\n",
    "    else:\n",
    "        raise Exception(f\"Failed to retrieve data. HTTP Status code: {response.status_code}\")\n",
    "\n",
    "# Example usage:\n",
    "api_keys = get_api_key()\n",
    "access_key = api_keys[\"access_key\"]\n",
    "token = api_keys[\"token\"]\n",
    "\n",
    "data = get_ura_data(access_key, token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONPATH=./src:$PYTHONPATH\n"
     ]
    }
   ],
   "source": [
    "%env PYTHONPATH=./src:$PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "property_id                                    2238\n",
       "street                           TAMPINES STREET 73\n",
       "project                                    PINEVALE\n",
       "marketsegment                                   OCR\n",
       "x                                       37836.26604\n",
       "y                                       39121.60695\n",
       "transaction_id                                65789\n",
       "area                                          120.0\n",
       "floorrange                                    06-10\n",
       "noofunits                                         1\n",
       "contractdate                                    523\n",
       "typeofsale                                        3\n",
       "price                                       1130000\n",
       "propertytype                  Executive Condominium\n",
       "district                                         18\n",
       "typeofarea                                   Strata\n",
       "tenure            99 yrs lease commencing from 1997\n",
       "Name: 65788, dtype: object"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/data.csv\")\n",
    "df[df['propertytype'] == 'Executive Condominium'].iloc[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../src/ml_service/data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[391], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../src/ml_service/data.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m df\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/envs/new-devt/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/envs/new-devt/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/envs/new-devt/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/envs/new-devt/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/envs/new-devt/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../src/ml_service/data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../src/ml_service/data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error\n",
    "\n",
    "def find_agg_price_neighbours(df, num_neighbours=2, agg_method='mean'):\n",
    "    \"\"\"\n",
    "    Finds the average price of the closest neighbors for each row in the DataFrame, \n",
    "    restricted to transactions within the same year.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): A DataFrame containing columns ['x-axis', 'y-axis', \n",
    "                                                           'transaction_month', \n",
    "                                                           'transaction_year', 'price'].\n",
    "    Returns:\n",
    "        pd.Series: A Series containing the average price of theclosest neighbors \n",
    "                   for each row.\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store the aggregated price of nearest neighbors for each row\n",
    "    agg_prices = []\n",
    "\n",
    "    # Group transactions by year\n",
    "    for year, group in df.groupby(['tx_month', 'tx_year']):\n",
    "        # Extract coordinates and prices from the same year group\n",
    "        coords = group[['x', 'y']].values\n",
    "        prices = group['price_per_sqm'].values\n",
    "        \n",
    "        # Use NearestNeighbors to find the closest neighbors\n",
    "        nbrs = NearestNeighbors(n_neighbors=num_neighbours, algorithm='auto').fit(coords)\n",
    "        distances, indices = nbrs.kneighbors(coords)\n",
    "        \n",
    "        # Calculate the median price of the nearest neighbors for each point\n",
    "        agg_price_per_row = []\n",
    "        for i in range(len(group)):\n",
    "            # Get indices of the closest neighbors in group\n",
    "            nearest_indices = indices[i]\n",
    "            # get their price per sqm\n",
    "            nearest_prices = prices[nearest_indices]\n",
    "            # calculate median of neighbours\n",
    "            if agg_method == 'median':\n",
    "                agg_price = int(np.median(nearest_prices))\n",
    "            elif agg_method == 'mean':\n",
    "                agg_price = int(np.mean(nearest_prices))\n",
    "            agg_price_per_row.append(agg_price)\n",
    "        \n",
    "        # Append results for this year to the main list\n",
    "        agg_prices.extend(agg_price_per_row)\n",
    "    \n",
    "    # Convert the list into a pandas Series and return it\n",
    "    return pd.Series(agg_prices, index=df.index)\n",
    "\n",
    "def feature_engineer(df):\n",
    "    raw = df[df['propertytype']=='Executive Condominium']\n",
    "    raw[\"lease_commencement\"] = raw[\"tenure\"].astype(str).str[-4:]\n",
    "    raw[\"tx_month\"] = raw[\"contractdate\"].astype(str).str[:-2].astype(int)\n",
    "    raw[\"tx_year\"] = raw[\"contractdate\"].astype(str).str[-2:].astype(int)\n",
    "    raw[\"price_per_sqm\"] = raw['price'].astype(int) // raw['area'].astype(int)\n",
    "    raw['neighbour_median_price_per_sqm'] = find_agg_price_neighbours(raw)\n",
    "    raw['num_years_from_tenure'] = (2000 + raw[\"tx_year\"].astype(int)) - raw[\"lease_commencement\"].astype(int)\n",
    "    \n",
    "    # Remove unimportant columns like noofunits, typeofarea (no variance),tenure, contractdate\n",
    "    return raw[['street', 'project', 'marketsegment',\n",
    "           'area', 'floorrange',\n",
    "           'typeofsale', 'district',\n",
    "           \"lease_commencement\", \"tx_month\", \"tx_year\", \"num_years_from_tenure\", \"price_per_sqm\"]] #, \"neighbour_median_price_per_sqm\"\n",
    "\n",
    "def split(dataset):\n",
    "    X = dataset[[col for col in dataset.columns if col != \"price_per_sqm\"]]\n",
    "    Y = dataset[\"price_per_sqm\"]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "def encode(X_train, X_test):\n",
    "    ohe = OneHotEncoder()\n",
    "    mms = MinMaxScaler()\n",
    "    continuous_vars = ['area'] # 'neighbour_median_price_per_sqm'\n",
    "\n",
    "    X_train_ohe = ohe.fit_transform(X_train[[col for col in X_train.columns if col not in continuous_vars]]).toarray()\n",
    "    X_train_scaled = mms.fit_transform(X_train[[col for col in X_train.columns if col in continuous_vars]])\n",
    "    X_train_final = np.concatenate([X_train_ohe, X_train_scaled], axis=-1)\n",
    "    \n",
    "    X_test_ohe = ohe.transform(X_test[[col for col in X_test.columns if col not in continuous_vars]]).toarray()\n",
    "    X_test_scaled = mms.fit_transform(X_test[[col for col in X_train.columns if col in continuous_vars]])\n",
    "    X_test_final = np.concatenate([X_test_ohe, X_test_scaled], axis=-1)\n",
    "    return X_train_final, X_test_final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_373322/157426104.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw[\"lease_commencement\"] = raw[\"tenure\"].astype(str).str[-4:]\n",
      "/tmp/ipykernel_373322/157426104.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw[\"tx_month\"] = raw[\"contractdate\"].astype(str).str[:-2].astype(int)\n",
      "/tmp/ipykernel_373322/157426104.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw[\"tx_year\"] = raw[\"contractdate\"].astype(str).str[-2:].astype(int)\n",
      "/tmp/ipykernel_373322/157426104.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw[\"price_per_sqm\"] = raw['price'].astype(int) // raw['area'].astype(int)\n",
      "/tmp/ipykernel_373322/157426104.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw['neighbour_median_price_per_sqm'] = find_agg_price_neighbours(raw)\n",
      "/tmp/ipykernel_373322/157426104.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw['num_years_from_tenure'] = (2000 + raw[\"tx_year\"].astype(int)) - raw[\"lease_commencement\"].astype(int)\n"
     ]
    }
   ],
   "source": [
    "dataset = feature_engineer(df)\n",
    "X_train, X_test, Y_train, Y_test = split(dataset)\n",
    "X_train_final, X_test_final = encode(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>street</th>\n",
       "      <th>project</th>\n",
       "      <th>marketsegment</th>\n",
       "      <th>area</th>\n",
       "      <th>floorrange</th>\n",
       "      <th>typeofsale</th>\n",
       "      <th>district</th>\n",
       "      <th>lease_commencement</th>\n",
       "      <th>tx_month</th>\n",
       "      <th>tx_year</th>\n",
       "      <th>num_years_from_tenure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106979</th>\n",
       "      <td>CANBERRA CRESCENT</td>\n",
       "      <td>PROVENCE RESIDENCE</td>\n",
       "      <td>OCR</td>\n",
       "      <td>97.0</td>\n",
       "      <td>11-15</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59645</th>\n",
       "      <td>ANCHORVALE CRESCENT</td>\n",
       "      <td>OLA</td>\n",
       "      <td>OCR</td>\n",
       "      <td>98.0</td>\n",
       "      <td>11-15</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106883</th>\n",
       "      <td>CANBERRA CRESCENT</td>\n",
       "      <td>PROVENCE RESIDENCE</td>\n",
       "      <td>OCR</td>\n",
       "      <td>82.0</td>\n",
       "      <td>01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108685</th>\n",
       "      <td>YISHUN CLOSE</td>\n",
       "      <td>NORTH GAIA</td>\n",
       "      <td>OCR</td>\n",
       "      <td>122.0</td>\n",
       "      <td>01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112796</th>\n",
       "      <td>OAKWOOD GROVE</td>\n",
       "      <td>LANDED HOUSING DEVELOPMENT</td>\n",
       "      <td>OCR</td>\n",
       "      <td>94.0</td>\n",
       "      <td>06-10</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91963</th>\n",
       "      <td>YIO CHU KANG ROAD</td>\n",
       "      <td>HUNDRED PALMS RESIDENCES</td>\n",
       "      <td>OCR</td>\n",
       "      <td>82.0</td>\n",
       "      <td>11-15</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125894</th>\n",
       "      <td>TAO CHING ROAD</td>\n",
       "      <td>LAKE LIFE</td>\n",
       "      <td>OCR</td>\n",
       "      <td>101.0</td>\n",
       "      <td>06-10</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96573</th>\n",
       "      <td>TAMPINES STREET 86</td>\n",
       "      <td>PARC CENTRAL RESIDENCES</td>\n",
       "      <td>OCR</td>\n",
       "      <td>103.0</td>\n",
       "      <td>01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60972</th>\n",
       "      <td>PASIR RIS DRIVE 4</td>\n",
       "      <td>THE ESPARIS</td>\n",
       "      <td>OCR</td>\n",
       "      <td>110.0</td>\n",
       "      <td>01-05</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>2002</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106870</th>\n",
       "      <td>CANBERRA CRESCENT</td>\n",
       "      <td>PROVENCE RESIDENCE</td>\n",
       "      <td>OCR</td>\n",
       "      <td>130.0</td>\n",
       "      <td>11-15</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11904 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     street                     project marketsegment   area  \\\n",
       "106979    CANBERRA CRESCENT          PROVENCE RESIDENCE           OCR   97.0   \n",
       "59645   ANCHORVALE CRESCENT                         OLA           OCR   98.0   \n",
       "106883    CANBERRA CRESCENT          PROVENCE RESIDENCE           OCR   82.0   \n",
       "108685         YISHUN CLOSE                  NORTH GAIA           OCR  122.0   \n",
       "112796        OAKWOOD GROVE  LANDED HOUSING DEVELOPMENT           OCR   94.0   \n",
       "...                     ...                         ...           ...    ...   \n",
       "91963     YIO CHU KANG ROAD    HUNDRED PALMS RESIDENCES           OCR   82.0   \n",
       "125894       TAO CHING ROAD                   LAKE LIFE           OCR  101.0   \n",
       "96573    TAMPINES STREET 86     PARC CENTRAL RESIDENCES           OCR  103.0   \n",
       "60972     PASIR RIS DRIVE 4                 THE ESPARIS           OCR  110.0   \n",
       "106870    CANBERRA CRESCENT          PROVENCE RESIDENCE           OCR  130.0   \n",
       "\n",
       "       floorrange  typeofsale  district lease_commencement  tx_month  tx_year  \\\n",
       "106979      11-15           1        27               2020         5       21   \n",
       "59645       11-15           1        19               2018         8       20   \n",
       "106883      01-05           1        27               2020         1       22   \n",
       "108685      01-05           1        27               2021         7       24   \n",
       "112796      06-10           1        24               2021        10       22   \n",
       "...           ...         ...       ...                ...       ...      ...   \n",
       "91963       11-15           3        19               2016         5       23   \n",
       "125894      06-10           3        22               2013         1       22   \n",
       "96573       01-05           1        18               2019         1       21   \n",
       "60972       01-05           3        18               2002         3       23   \n",
       "106870      11-15           1        27               2020        11       21   \n",
       "\n",
       "        num_years_from_tenure  \n",
       "106979                      1  \n",
       "59645                       2  \n",
       "106883                      2  \n",
       "108685                      3  \n",
       "112796                      1  \n",
       "...                       ...  \n",
       "91963                       7  \n",
       "125894                      9  \n",
       "96573                       2  \n",
       "60972                      21  \n",
       "106870                      1  \n",
       "\n",
       "[11904 rows x 11 columns]"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(model, X_train, Y_train, X_test):\n",
    "    model.fit(X_train, Y_train)    \n",
    "    return model.predict(X_test)\n",
    "\n",
    "def evaluate(test, pred):\n",
    "    return {\n",
    "        \"mean_absolute_error\": mean_absolute_error(test, pred),\n",
    "        \"root_mean_squared_error\": root_mean_squared_error(test, pred),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_absolute_error': 1180.2881309972743,\n",
       " 'root_mean_squared_error': 1501.5032052588174}"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators = 1000, max_depth=3, random_state=0)\n",
    "pred = train_predict(model, X_train_final, Y_train, X_test_final)\n",
    "evaluate(Y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_absolute_error': 478.22850861339145,\n",
       " 'root_mean_squared_error': 635.3362260773346}"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": 300,\n",
    "    \"max_depth\": 3,\n",
    "    \"min_samples_split\": 3,\n",
    "    \"learning_rate\": 0.3,\n",
    "    \"loss\": \"squared_error\",\n",
    "}\n",
    "model = GradientBoostingRegressor(**params)\n",
    "pred = train_predict(model, X_train_final, Y_train, X_test_final)\n",
    "evaluate(Y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_absolute_error': 474.82700705408126,\n",
       " 'root_mean_squared_error': 609.1851383209308}"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "pred = train_predict(model, X_train_final, Y_train, X_test_final)\n",
    "evaluate(Y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_id                                    2238\n",
    "street                           TAMPINES STREET 73\n",
    "project                                    PINEVALE\n",
    "marketsegment                                   OCR\n",
    "x                                       37836.26604\n",
    "y                                       39121.60695\n",
    "transaction_id                                65789\n",
    "area                                          120.0\n",
    "floorrange                                    06-10\n",
    "noofunits                                         1\n",
    "contractdate                                    523\n",
    "typeofsale                                        3\n",
    "price                                       1130000\n",
    "propertytype                  Executive Condominium\n",
    "district                                         18\n",
    "typeofarea                                   Strata\n",
    "tenure            99 yrs lease commencing from 1997"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# curl -X 'POST' \\\n",
    "#   'http://0.0.0.0:8000/predict/' \\\n",
    "#   -H 'Content-Type: application/json' \\\n",
    "#   -d \"{\n",
    "#     street: 'TAMPINES STREET 73' \\\n",
    "#     project: 'PINEVALE' \\\n",
    "#     marketsegment: 'OCR' \\\n",
    "#     x: '37836.26604' \\\n",
    "#     y: '39121.60695' \\\n",
    "#     area: '120.0' \\\n",
    "#     floorrange: '06-10' \\\n",
    "#     noofunits: '1' \\\n",
    "#     contractdate: '125' \\\n",
    "#     typeofsale: '3' \\\n",
    "#     propertytype: 'Executive Condominium' \\\n",
    "#     district: '18' \\\n",
    "#     typeofarea: 'Strata' \\\n",
    "#     tenure: '99 yrs lease commencing from 1997'\n",
    "# }\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# # URL of the FastAPI prediction endpoint\n",
    "# url = \"http://0.0.0.1:8000/predict/\"\n",
    "\n",
    "# # Example data to send to the model (as a dictionary)\n",
    "# data = {\n",
    "#     \"street\": \"TAMPINES STREET 73\",\n",
    "#     \"project\": \"PINEVALE\",\n",
    "#     \"marketSegment\": \"OCR\",\n",
    "#     \"x\": \"37836.26604\",\n",
    "#     \"y\": \"39121.60695\",\n",
    "#     \"area\": '120.0',\n",
    "#     \"floorRange\": \"06-10\",\n",
    "#     \"noOfUnits\": '1',\n",
    "#     \"contractDate\": \"125\",\n",
    "#     \"typeOfSale\": \"3\",\n",
    "#     \"propertyType\": \"Executive Condominium\",\n",
    "#     \"district\": \"18\",\n",
    "#     \"typeOfArea\": \"Strata\",\n",
    "#     \"tenure\": \"99 yrs lease commencing from 1997\"\n",
    "# }\n",
    "\n",
    "# # Send a POST request with the data as JSON\n",
    "# response = requests.post(url, json=data)\n",
    "# print(response)\n",
    "\n",
    "# # Check the response status code and content\n",
    "# if response.status_code == 200:\n",
    "#     print(\"Prediction:\", response.json())\n",
    "# else:\n",
    "#     print(\"Failed to connect:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to connect: 500\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# URL of the FastAPI prediction endpoint\n",
    "url = \"http://0.0.0.0:8000/predict/\"\n",
    "\n",
    "# Example data to send to the model (the JSON payload)\n",
    "data = {\n",
    "    \"street\": \"TAMPINES STREET 73\",\n",
    "    \"project\": \"PINEVALE\",\n",
    "    \"marketsegment\": \"OCR\",\n",
    "    \"x\": \"37836.26604\",\n",
    "    \"y\": \"39121.60695\",\n",
    "    \"area\": \"120.0\",\n",
    "    \"floorrange\": \"06-10\",\n",
    "    \"noofunits\": \"1\",\n",
    "    \"contractdate\": \"125\",\n",
    "    \"typeofsale\": \"3\",\n",
    "    \"district\": \"18\",\n",
    "    \"typeofarea\": \"Strata\",\n",
    "    \"tenure\": \"99 yrs lease commencing from 1997\"\n",
    "}\n",
    "\n",
    "# Send a POST request with the data as JSON\n",
    "response = requests.post(url, json=data)\n",
    "\n",
    "# Check the response status code and content\n",
    "if response.status_code == 200:\n",
    "    print(\"Prediction:\", response.json())\n",
    "else:\n",
    "    print(\"Failed to connect:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['street', 'project', 'marketsegment', 'floorrange', 'typeofsale', 'district', 'lease_commencement', 'tx_month', 'tx_year', 'num_years_from_tenure']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
